{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import librarires"
      ],
      "metadata": {
        "id": "B79PLTTWZmro"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQNgMJhBZf3v"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier"
      ],
      "metadata": {
        "id": "qEtqwPh8ZrHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data pre-processing"
      ],
      "metadata": {
        "id": "qGqcjSk4Z4Al"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0QlYwkveZ0r4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXC2ZKGc7x6L"
      },
      "outputs": [],
      "source": [
        "train_data=pd.read_csv('drive/MyDrive/Colab Notebooks/train_hybrid.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4aff832-88fd-41c3-e913-ed891b4ea1ab",
        "id": "mUiMFwvj7x6M"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2880, 2496)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad9daad2-55a4-4044-cacf-04f3dc45e364",
        "id": "CMzpfB0C7x6N"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "float64    1275\n",
              "int64      1220\n",
              "object        1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train_data.dtypes.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uM3aL_RE7x6N"
      },
      "outputs": [],
      "source": [
        "# Below code gives percentage of null in every column\n",
        "null_percentage = train_data.isnull().sum()/train_data.shape[0]*100\n",
        "\n",
        "# Below code gives list of columns having more than 60% null\n",
        "col_to_drop = null_percentage[null_percentage>60].keys()\n",
        "\n",
        "train_data = train_data.drop(col_to_drop, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41ba77ec-7bb1-4285-bf90-792422b120cc",
        "id": "-VvidBBm7x6N"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2880, 2335)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70712035-293e-403b-a5e0-dc3c609a03dd",
        "id": "C5Yx662I7x6O"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MINsssN    1617\n",
              "MAXsssN    1617\n",
              "MDEO-12    1400\n",
              "MDEO-11    1339\n",
              "MAXaaaC    1326\n",
              "MINaaaC    1326\n",
              "MDEN-23    1287\n",
              "MDEC-11    1281\n",
              "MINssO     1212\n",
              "MAXssO     1212\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_data.isna().sum().sort_values(ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "721ed17f-5ef9-4e05-bfa3-af20dd5bcca6",
        "id": "Ttp52qcP7x6O"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "float64    455\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# get the columns with null values\n",
        "null_cols = train_data.columns[train_data.isnull().any()]\n",
        "\n",
        "# get the count of each data type for columns with null values\n",
        "dtype_counts = train_data[null_cols].dtypes.value_counts()\n",
        "dtype_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoRRrM-77x6P"
      },
      "outputs": [],
      "source": [
        "# get the mean of the columns with float data type\n",
        "mean_values = train_data.select_dtypes(include=['float']).mean()\n",
        "\n",
        "# replace missing values with mean for float columns\n",
        "train_data[train_data.select_dtypes(include=['float']).columns] = train_data.select_dtypes(include=['float']).fillna(mean_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cV9sHlop7x6P"
      },
      "outputs": [],
      "source": [
        "train_data=train_data.drop('Name',axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34d9874b-0397-4c16-93d3-6f49970f144d",
        "id": "8ApVbz9l7x6R"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2880, 2334)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "train_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "X as the feature matrix, including all descriptors, and y as the response variable"
      ],
      "metadata": {
        "id": "ExVFh_SUai9M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAPTD1wZ7x6S"
      },
      "outputs": [],
      "source": [
        "X=train_data.drop('cls',axis=1)\n",
        "y=train_data['cls']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature selection"
      ],
      "metadata": {
        "id": "LUcdxGPUaoJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# Define the LinearSVC model\n",
        "svc_model = LinearSVC(penalty=\"l1\", dual=False)\n",
        "\n",
        "# Initialize the SelectFromModel object without threshold\n",
        "selector = SelectFromModel(estimator=svc_model, threshold='median')\n",
        "\n",
        "# Fit the selector to the data and transform it\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "\n",
        "# Get the indices of the selected features\n",
        "selected_indices = selector.get_support(indices=True)\n",
        "\n",
        "# Get the selected feature names\n",
        "selected_features = X.columns[selected_indices]\n",
        "\n",
        "# Create the final DataFrame with selected features\n",
        "X = X[selected_features]"
      ],
      "metadata": {
        "id": "aeMMUhr8akG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross validation and model generation and ROC curve"
      ],
      "metadata": {
        "id": "hE8wc8luatVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary of models\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=500, max_features='log2', random_state=42,\n",
        "                                             max_depth=5, min_samples_split=3, min_samples_leaf=2, bootstrap=True),\n",
        "    'XGBoost': xgb.XGBClassifier(learning_rate=0.1, max_depth=3,subsample=0.7,colsample_bytree=0.6, reg_lambda=0.5, n_estimators=300),\n",
        "    'GB': GradientBoostingClassifier(n_estimators=400, learning_rate=0.01,min_samples_split=5,min_samples_leaf=4,max_depth=3,subsample=0.8,max_features='sqrt',  loss='log_loss',random_state=42),\n",
        "    'ET': ExtraTreesClassifier(n_estimators=500, criterion='gini', max_features='sqrt', max_depth=6,\n",
        "                               random_state=42, min_samples_split=2, bootstrap=False, verbose=0),\n",
        "    'AdaBoost': AdaBoostClassifier(n_estimators=300, learning_rate=1.0, algorithm='SAMME', random_state=42,\n",
        "                                   estimator=None),\n",
        "    'LightGBM': lgb.LGBMClassifier(max_depth=7,learning_rate=0.01,num_leaves=50),\n",
        "}\n",
        "\n",
        "# Add XGBoost and GB to the Voting Classifier\n",
        "voting_clf = VotingClassifier(estimators=[('XGBoost', models['XGBoost']), ('GB', models['GB'])], voting='soft')\n",
        "\n",
        "# Add the Voting Classifier to the models dictionary\n",
        "models[' Voting (XGB+GB)'] = voting_clf\n",
        "\n",
        "# Create subplots\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Initialize the result dictionaries\n",
        "train_results = {}\n",
        "test_results = {}\n",
        "\n",
        "# Loop through each model\n",
        "for model_name, model in models.items():\n",
        "    # Fit the model\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Perform cross-validation and get predicted probabilities for training set\n",
        "    y_probas_train = cross_val_predict(model, X, y, cv=10, method=\"predict_proba\")[:, 1]\n",
        "\n",
        "    # Calculate AUC for training set\n",
        "    fpr_train, tpr_train, _ = roc_curve(y, y_probas_train)\n",
        "    auc_train = roc_auc_score(y, y_probas_train)\n",
        "\n",
        "    # Calculate Matthews Correlation Coefficient\n",
        "    mcc = matthews_corrcoef(y, (y_probas_train > 0.5).astype(int))\n",
        "\n",
        "    # Calculate Sensitivity and Specificity\n",
        "    tn, fp, fn, tp = confusion_matrix(y, (y_probas_train > 0.5).astype(int)).ravel()\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    accuracy_train = accuracy_score(y, (y_probas_train > 0.5).astype(int))\n",
        "\n",
        "    train_results[model_name] = {\n",
        "        'AUC': auc_train,\n",
        "        'MCC': mcc,\n",
        "        'Sensitivity': sensitivity,\n",
        "        'Specificity': specificity,\n",
        "        'Accuracy': accuracy_train\n",
        "    }\n",
        "\n",
        "    # Plot ROC curve for training set\n",
        "    axs[0].plot(fpr_train, tpr_train, label=f'{model_name} (AUC = {auc_train:.2f}')\n",
        "    axs[0].set_xlabel('False Positive Rate')\n",
        "    axs[0].set_ylabel('True Positive Rate')\n",
        "    axs[0].set_title('ROC Curve - Ten-fold cross-validation')\n",
        "    axs[0].legend()\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy for the test set\n",
        "    accuracy_test = accuracy_score(y_test, y_pred)\n",
        "    test_results[model_name] = {'Test Accuracy': accuracy_test}\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_probas_test = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Calculate AUC for the test set\n",
        "    fpr_test, tpr_test, _ = roc_curve(y_test, y_probas_test)\n",
        "    auc_test = roc_auc_score(y_test, y_probas_test)\n",
        "\n",
        "    # Calculate Matthews Correlation Coefficient\n",
        "    mcc = matthews_corrcoef(y_test, (y_probas_test > 0.5).astype(int))\n",
        "\n",
        "    # Calculate Sensitivity and Specificity\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, (y_probas_test > 0.5).astype(int)).ravel()\n",
        "    sensitivity = tp / (tp + fn)\n",
        "\n",
        "\n",
        "    # Plot ROC curve for test set\n",
        "    axs[1].plot(fpr_test, tpr_test, label=f'{model_name} (AUC = {auc_test:.2f}')\n",
        "    axs[1].set_xlabel('False Positive Rate')\n",
        "    axs[1].set_ylabel('True Positive Rate')\n",
        "    axs[1].set_title('ROC Curve - Test Set')\n",
        "    axs[1].legend()\n",
        "\n",
        "    test_results[model_name]['AUC'] = auc_test\n",
        "    test_results[model_name]['MCC'] = mcc\n",
        "    test_results[model_name]['Sensitivity'] = sensitivity\n",
        "    test_results[model_name]['Specificity'] = tn / (tn + fp)\n",
        "\n",
        "    # Print results\n",
        "    print(f'{model_name} Metrics of Training Set:')\n",
        "    for metric, value in train_results[model_name].items():\n",
        "        print(f'{metric}: {value:.4f}')\n",
        "\n",
        "    print(f'{model_name} Metrics of Test Set:')\n",
        "    for metric, value in test_results[model_name].items():\n",
        "        print(f'{metric}: {value:.4f}')\n",
        "\n",
        "    print('-' * 30)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZoHXgZD7azzO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}